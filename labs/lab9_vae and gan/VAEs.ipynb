{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE888 Lab9\n",
    "### VAE encoder network\n",
    "**Date**: 11 March 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (28, 28, 1)\n",
    "batch_size = 16\n",
    "latent_dim = 2 # Dimensionality of the latent space: a 2D plane\n",
    "input_img = keras.Input(shape=img_shape)\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_img)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "# The input image ends up being encoded into these two parameters\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "z_log_var = layers.Dense(latent_dim)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/BiasAdd:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the code for using `z_mean` and `z_log_var`, the parameters of the statistical distribution\n",
    "assumed to have produced `input_img`, to generate a latent space point `z`.\n",
    "Here, you wrap some arbitrary code (built on top of Keras backend primitives) into a\n",
    "Lambda layer. In Keras, everything needs to be a layer, so code that isn’t part of a builtin\n",
    "layer should be wrapped in a `Lambda` (or in a custom layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent-space-sampling function\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_9/add:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE decoder network, mapping latent space points to images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following listing shows the decoder implementation. You reshape the vector `z` to\n",
    "the dimensions of an image and then use a few convolution layers to obtain a final\n",
    "image output that has the same dimensions as the original `input_img`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = layers.Input(K.int_shape(z)[1:]) # Input where you’ll feed z\n",
    "\n",
    "x = layers.Dense(np.prod(shape_before_flattening[1:]), \n",
    "                 activation='relu')(decoder_input)\n",
    "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "x = layers.Conv2DTranspose(32, 3,padding='same',\n",
    "                           activation='relu',strides=(2, 2))(x)\n",
    "x = layers.Conv2D(1, 3,padding='same',activation='sigmoid')(x)\n",
    "decoder = Model(decoder_input, x)\n",
    "z_decoded = decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layer used to compute the VAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVariationalLayer(keras.layers.Layer):\n",
    "    \n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        x = K.flatten(x)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        kl_loss = -5e-4 * K.mean(\n",
    "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "    \n",
    "    #You implement custom layers You don't use by writing a call method.\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return x # You don't use this output, but the layer must return something.\n",
    "    \n",
    "y = CustomVariationalLayer()([input_img, z_decoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Output \"custom_variational_layer_2\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_2\" during training.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 28, 28, 32)    320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 14, 14, 64)    18496       conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 14, 14, 64)    36928       conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 14, 14, 64)    36928       conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 12544)         0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            401440      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             66          dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             66          dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (None, 2)             0           dense_2[0][0]                    \n",
      "                                                                   dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_3 (Model)                  (None, 28, 28, 1)     56385       lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "custom_variational_layer_2 (Cust [(None, 28, 28, 1), ( 0           input_1[0][0]                    \n",
      "                                                                   model_3[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 550,629\n",
      "Trainable params: 550,629\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "vae = Model(input_img, y)\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n",
    "vae.summary()\n",
    "\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train\t: (60000, 28, 28, 1) \n",
      " first object [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0117647061124444], [0.07058823853731155], [0.07058823853731155], [0.07058823853731155], [0.4941176474094391], [0.5333333611488342], [0.686274528503418], [0.10196078568696976], [0.6509804129600525], [1.0], [0.9686274528503418], [0.49803921580314636], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.11764705926179886], [0.1411764770746231], [0.3686274588108063], [0.6039215922355652], [0.6666666865348816], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.8823529481887817], [0.6745098233222961], [0.9921568632125854], [0.9490196108818054], [0.7647058963775635], [0.250980406999588], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.1921568661928177], [0.9333333373069763], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9843137264251709], [0.364705890417099], [0.32156863808631897], [0.32156863808631897], [0.21960784494876862], [0.15294118225574493], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.07058823853731155], [0.8588235378265381], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.7764706015586853], [0.7137255072593689], [0.9686274528503418], [0.9450980424880981], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.3137255012989044], [0.6117647290229797], [0.41960784792900085], [0.9921568632125854], [0.9921568632125854], [0.8039215803146362], [0.04313725605607033], [0.0], [0.16862745583057404], [0.6039215922355652], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.054901961237192154], [0.003921568859368563], [0.6039215922355652], [0.9921568632125854], [0.3529411852359772], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.545098066329956], [0.9921568632125854], [0.7450980544090271], [0.007843137718737125], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.04313725605607033], [0.7450980544090271], [0.9921568632125854], [0.27450981736183167], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.13725490868091583], [0.9450980424880981], [0.8823529481887817], [0.6274510025978088], [0.42352941632270813], [0.003921568859368563], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.3176470696926117], [0.9411764740943909], [0.9921568632125854], [0.9921568632125854], [0.46666666865348816], [0.09803921729326248], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.1764705926179886], [0.729411780834198], [0.9921568632125854], [0.9921568632125854], [0.5882353186607361], [0.10588235408067703], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.062745101749897], [0.364705890417099], [0.9882352948188782], [0.9921568632125854], [0.7333333492279053], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.9764705896377563], [0.9921568632125854], [0.9764705896377563], [0.250980406999588], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.18039216101169586], [0.5098039507865906], [0.7176470756530762], [0.9921568632125854], [0.9921568632125854], [0.8117647171020508], [0.007843137718737125], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.15294118225574493], [0.5803921818733215], [0.8980392217636108], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9803921580314636], [0.7137255072593689], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0941176488995552], [0.4470588266849518], [0.8666666746139526], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.7882353067398071], [0.30588236451148987], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.09019608050584793], [0.25882354378700256], [0.8352941274642944], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.7764706015586853], [0.3176470696926117], [0.007843137718737125], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.07058823853731155], [0.6705882549285889], [0.8588235378265381], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.7647058963775635], [0.3137255012989044], [0.03529411926865578], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.21568627655506134], [0.6745098233222961], [0.886274516582489], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.95686274766922], [0.5215686559677124], [0.04313725605607033], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.5333333611488342], [0.9921568632125854], [0.9921568632125854], [0.9921568632125854], [0.8313725590705872], [0.529411792755127], [0.5176470875740051], [0.062745101749897], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]]\n",
      "\n",
      "x_test\t: (10000, 28, 28, 1) \n",
      " first object [[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.3294117748737335], [0.7254902124404907], [0.6235294342041016], [0.5921568870544434], [0.23529411852359772], [0.1411764770746231], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.8705882430076599], [0.9960784316062927], [0.9960784316062927], [0.9960784316062927], [0.9960784316062927], [0.9450980424880981], [0.7764706015586853], [0.7764706015586853], [0.7764706015586853], [0.7764706015586853], [0.7764706015586853], [0.7764706015586853], [0.7764706015586853], [0.7764706015586853], [0.6666666865348816], [0.20392157137393951], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.26274511218070984], [0.4470588266849518], [0.2823529541492462], [0.4470588266849518], [0.6392157077789307], [0.8901960849761963], [0.9960784316062927], [0.8823529481887817], [0.9960784316062927], [0.9960784316062927], [0.9960784316062927], [0.9803921580314636], [0.8980392217636108], [0.9960784316062927], [0.9960784316062927], [0.5490196347236633], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.06666667014360428], [0.25882354378700256], [0.054901961237192154], [0.26274511218070984], [0.26274511218070984], [0.26274511218070984], [0.23137255012989044], [0.08235294371843338], [0.9254902005195618], [0.9960784316062927], [0.4156862795352936], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.32549020648002625], [0.9921568632125854], [0.8196078538894653], [0.07058823853731155], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.08627451211214066], [0.9137254953384399], [1.0], [0.32549020648002625], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.5058823823928833], [0.9960784316062927], [0.9333333373069763], [0.1725490242242813], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.23137255012989044], [0.9764705896377563], [0.9960784316062927], [0.24313725531101227], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.5215686559677124], [0.9960784316062927], [0.7333333492279053], [0.019607843831181526], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.03529411926865578], [0.8039215803146362], [0.9725490212440491], [0.22745098173618317], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4941176474094391], [0.9960784316062927], [0.7137255072593689], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.29411765933036804], [0.9843137264251709], [0.9411764740943909], [0.2235294133424759], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.07450980693101883], [0.8666666746139526], [0.9960784316062927], [0.6509804129600525], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0117647061124444], [0.7960784435272217], [0.9960784316062927], [0.8588235378265381], [0.13725490868091583], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.14901961386203766], [0.9960784316062927], [0.9960784316062927], [0.3019607961177826], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.12156862765550613], [0.8784313797950745], [0.9960784316062927], [0.45098039507865906], [0.003921568859368563], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.5215686559677124], [0.9960784316062927], [0.9960784316062927], [0.20392157137393951], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.239215686917305], [0.9490196108818054], [0.9960784316062927], [0.9960784316062927], [0.20392157137393951], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4745098054409027], [0.9960784316062927], [0.9960784316062927], [0.8588235378265381], [0.1568627506494522], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4745098054409027], [0.9960784316062927], [0.8117647171020508], [0.07058823853731155], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\\t:\",x_train.shape, \"\\n first object\", x_train[0].tolist())\n",
    "print(\"\\nx_test\\t:\",x_test.shape, \"\\n first object\", x_test[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 532s - loss: 0.2053 - val_loss: 0.1940\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 503s - loss: 0.1916 - val_loss: 0.1891\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 491s - loss: 0.1880 - val_loss: 0.1863\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 510s - loss: 0.1859 - val_loss: 0.1855\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 563s - loss: 0.1845 - val_loss: 0.1843\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 590s - loss: 0.1835 - val_loss: 0.1830\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 715s - loss: 0.1832 - val_loss: 0.1829\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 681s - loss: 189359002.0984 - val_loss: 2.0420\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 594s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 655s - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x125c30470>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x=x_train, y=None, shuffle=True, epochs=10, \n",
    "        batch_size=batch_size, validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/colors.py:897: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/ma/core.py:718: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1391f8470>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "n = 15\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
    "        x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "            j * digit_size: (j + 1) * digit_size] = digit\n",
    "        \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exersice**: To play further with image generation, I suggest working with the Largescale Celeb Faces\n",
    "    Attributes (CelebA) dataset. It’s a free-to-download image dataset containing more than \n",
    "    200,000 celebrity portraits. It’s great for experimenting with concept vectors in particular—it \n",
    "    definitely beats MNIST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
