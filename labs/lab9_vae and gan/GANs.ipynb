{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "s6nX-Ecsw0Z6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CE888 Lab9\n",
        "### GAN generator netowrk\n",
        "**Date**: 11 March 2019"
      ]
    },
    {
      "metadata": {
        "id": "APinNJ9fwwYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81be0656-4677-4174-b8d0-de6419249cdc"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "swS5uQDxGIQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "4b5dc94a-45d5-48e0-ff4e-77ec8187774f"
      },
      "cell_type": "code",
      "source": [
        "parameters={0:{\"gen_act\":\"tanh\", \"cls_act\":\"sigmoid\",\\\n",
        "               \"disc_loss\":\"binary_crossentropy\"},\\\n",
        "            1:{\"gen_act\":\"sigmoid\", \"cls_act\":\"sigmoid\", \\\n",
        "               \"disc_loss\":\"binary_crossentropy\"},\\\n",
        "            2:{\"gen_act\":\"tanh\", \"cls_act\":\"tanh\", \\\n",
        "               \"disc_loss\":\"binary_crossentropy\"},\\\n",
        "            3:{\"gen_act\":\"tanh\", \"cls_act\":\"sigmoid\", \\\n",
        "               \"disc_loss\":\"mean_squared_error\"}}\n",
        "\n",
        "para_id=int(input(\"Select parameters from [%s]: \" % \\\n",
        "              \",\".join([str(i) for i in list(parameters.keys())])))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select parameters from [0,1,2,3]: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hSOaSEGwwwYY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GAN generator network"
      ]
    },
    {
      "metadata": {
        "id": "JKqWOABSwwYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "34fa8795-4ea7-4f00-f96f-79a376a718b6"
      },
      "cell_type": "code",
      "source": [
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "# Transforms the input into a 16 × 16 128-channel feature map\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# Upsamples to 32 × 32\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# Produces a 32 × 32 1-channel feature map (shape of a CIFAR10 image)\n",
        "x = layers.Conv2D(channels, 7, activation=parameters[para_id][\"gen_act\"], \\\n",
        "                  padding='same')(x)\n",
        "\n",
        "# Instantiates the generator model, which maps the input of shape (latent_dim,) \n",
        "#into an image of shape (32, 32, 3)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y9YOYTz_wwZE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The GAN discriminator network"
      ]
    },
    {
      "metadata": {
        "id": "BB-dFewTwwZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "outputId": "0caa5327-abcd-4aa7-f134-e444acb3e65b"
      },
      "cell_type": "code",
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# One dropout layer: an important trick\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "# Classification layer\n",
        "x = layers.Dense(1, activation=parameters[para_id][\"cls_act\"])(x)\n",
        "\n",
        "# Instantiates the discriminator model, which turns a (32, 32, 3) input into \n",
        "# a binary classification decision (fake/real)\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "\n",
        "# Uses gradient clipping (by value) in the optimizer and To stabilize training, \n",
        "# uses learning-rate decay\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008,clipvalue=1.0,\\\n",
        "                                                   decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer,\\\n",
        "                      loss=parameters[para_id][\"disc_loss\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C4kPvzKnwwZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Adversarial network"
      ]
    },
    {
      "metadata": {
        "id": "AScMbADbwwZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sets discriminator weights to non-trainable\n",
        "# (this will only apply to the gan model)\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6GPT7_i__C7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "09f71320-248d-40a9-aaae-c74dab577e65"
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Loads CIFAR10 data\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Selects frog images (class 6)\n",
        "x_train = x_train[y_train.flatten() == 6]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 111s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_hfiRFMh_Elf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2b61b686-7330-4b40-e42b-71b68c294bb8"
      },
      "cell_type": "code",
      "source": [
        "print(\"x_train\\t:\",x_train.shape)\n",
        "print(\"y_train\\t:\",y_train.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train\t: (5000, 32, 32, 3)\n",
            "y_train\t: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LOVwSZWv95ah",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the netowrk\n",
        "x_train = x_train.reshape(\n",
        "    (x_train.shape[0],) +\n",
        "    (height, width, channels)).astype('float32') / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OlJ6lxfy9uer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb79c14e-f2e3-4618-8213-35422d194740"
      },
      "cell_type": "code",
      "source": [
        "# create output picture folder\n",
        "import os\n",
        "\n",
        "save_dir = \"output_files\"\n",
        "if os.path.exists(save_dir)==False:\n",
        "  os.mkdir(save_dir)\n",
        "  print(\"<%s> directory is created.\" % save_dir)\n",
        "else:\n",
        "  print(\"<%s> directory already exists.\" % save_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<output_files> directory is created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BYJHnU-swwaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "ecbd92ec-62b1-44d6-a1ec-9eb7ac1ee22c"
      },
      "cell_type": "code",
      "source": [
        "# set parameters for random sampling\n",
        "iterations = 10000\n",
        "batch_size = 20\n",
        "\n",
        "start = 0\n",
        "# Samples random points in the latent space\n",
        "for step in range(iterations):\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "# Decodes them to fake images    \n",
        "generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "# Combines them with real images \n",
        "stop = start + batch_size\n",
        "real_images = x_train[start: stop]\n",
        "combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "# Trains the discriminator\n",
        "d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "# Samples random points in the latent space\n",
        "random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
        "\n",
        "# Assembles latent space labels that say “these are all real images”\n",
        "# (it’s a lie!)\n",
        "misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "# Trains the generator (via the gan model, where the discriminator weights\n",
        "# are frozen)\n",
        "a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "\n",
        "start += batch_size\n",
        "if start > len(x_train) - batch_size: \n",
        "    start = 0\n",
        "    \n",
        "if step % 100 == 0: \n",
        "    gan.save_weights('gan.h5')\n",
        "    \n",
        "print('Discriminator loss:', d_loss)\n",
        "print('Adversarial loss:', a_loss)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator loss: 0.25884765\n",
            "Adversarial loss: 0.26298517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rS2LZouVwwar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create and store output pictures\n",
        "img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "img.save(save_dir + \"/generated_frog_%s_%d.png\" % (str(step), para_id))\n",
        "         \n",
        "img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "img.save(save_dir+ \"/real_frog_%s_%d.png\" % (str(step), para_id))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAOCR22HCiNw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Results with different parameters:\n",
        "\n",
        "|#|GAN generator activation function|Classification layer activation function|Discriminator loss functio|discriminator loss|adversarial loss|\n",
        "|--------| --------|--------|--------|--------|--------|\n",
        "|00|tanh|sigmoid|binary_crossentropy|0.7097865|0.29890946|\n",
        "|01|sigmoid|sigmoid|binary_crossentropy|0.69281924|3.2741482e-07|\n",
        "|02|tanh|tanh|binary_crossentropy|8.457808|0.6745621|\n",
        "|03|tanh|sigmoid|mean_squared_error|0.25884765|0.26298517|"
      ]
    },
    {
      "metadata": {
        "id": "qSnVIkszH86e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}